{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NTELS\\miniconda3\\envs\\doc-chunker\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from frony_document_manager.parser import ParserTXT\n",
    "from frony_document_manager.parser import ParserPDF\n",
    "from frony_document_manager.parser import ParserPPTX\n",
    "from frony_document_manager.parser import ParserPDFImage\n",
    "from frony_document_manager.parser import ParserImage\n",
    "\n",
    "from frony_document_manager.chunker import RuleBasedTextChunker\n",
    "from frony_document_manager.chunker import LLMBasedTextChunker\n",
    "from frony_document_manager.chunker import LLMBasedImageChunker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RuleBasedTextChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1 Introduction\\nRecurrent neural networks, lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Figure 1: The Transformer - model architecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Scaled Dot-Product Attention Multi-Head Attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>output values. These are concatenated and once...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Table 1: Maximum path lengths, per-layer compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>n\\nlength is smaller than the representation d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Table 2: The Transformer achieves better BLEU ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Table 3: Variations on the Transformer archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Table 4: The Transformer generalizes well to E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[5] Kyunghyun Cho, Bart van Merrienboer, Cagla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[25] Mitchell P Marcus, Mary Ann Marcinkiewicz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|    | Vi   | atio   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|--:|\\n| 0 |\\n| 1 |\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|--:|\\n| 0 |\\n| 1 |\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                       page_content\n",
       "0             1  Provided proper attribution is provided, Googl...\n",
       "1             2  1 Introduction\\nRecurrent neural networks, lon...\n",
       "2             3  Figure 1: The Transformer - model architecture...\n",
       "3             4  Scaled Dot-Product Attention Multi-Head Attent...\n",
       "4             5  output values. These are concatenated and once...\n",
       "5             6  Table 1: Maximum path lengths, per-layer compl...\n",
       "6             7  n\\nlength is smaller than the representation d...\n",
       "7             8  Table 2: The Transformer achieves better BLEU ...\n",
       "8             9  Table 3: Variations on the Transformer archite...\n",
       "9            10  Table 4: The Transformer generalizes well to E...\n",
       "10           11  [5] Kyunghyun Cho, Bart van Merrienboer, Cagla...\n",
       "11           12  [25] Mitchell P Marcus, Mary Ann Marcinkiewicz...\n",
       "12           13  Input-Input Layer5\\n<표>\\n|    | Vi   | atio   ...\n",
       "13           14  Input-Input Layer5\\n<표>\\n|--:|\\n| 0 |\\n| 1 |\\n...\n",
       "14           15  Input-Input Layer5\\n<표>\\n|--:|\\n| 0 |\\n| 1 |\\n..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ParserPDF()\n",
    "df = parser.parse(\"test_files/test_pdf.pdf\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provided proper attribution is provided, Google hereby grants permission to\n",
      "reproduce the tables and figures in this paper solely for use in journalistic or\n",
      "scholarly works.\n",
      "Attention Is All You Need\n",
      "3202 guA 2  ]LC.sc[  7v26730.6071:viXra\n",
      "Ashish Vaswani∗ Noam Shazeer∗ Niki Parmar∗ Jakob Uszkoreit∗\n",
      "Google Brain Google Brain Google Research Google Research\n",
      "avaswani@google.com noam@google.com nikip@google.com usz@google.com\n",
      "†\n",
      "Llion Jones∗ Aidan N. Gomez∗ Łukasz Kaiser∗\n",
      "Google Research University of Toronto Google Brain\n",
      "llion@google.com aidan@cs.toronto.edu lukaszkaiser@google.com\n",
      "‡\n",
      "Illia Polosukhin∗\n",
      "illia.polosukhin@gmail.com\n",
      "Abstract\n",
      "The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks that include an encoder and a decoder. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer,\n",
      "based solely on attention mechanisms, dispensing with recurrence and convolutions\n",
      "entirely. Experiments on two machine translation tasks show these models to\n",
      "be superior in quality while being more parallelizable and requiring significantly\n",
      "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\n",
      "to-German translation task, improving over the existing best results, including\n",
      "ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\n",
      "our model establishes a new single-model state-of-the-art BLEU score of 41.8 after\n",
      "training for 3.5 days on eight GPUs, a small fraction of the training costs of the\n",
      "best models from the literature. We show that the Transformer generalizes well to\n",
      "other tasks by applying it successfully to English constituency parsing both with\n",
      "large and limited training data.\n",
      "∗Equal\n",
      "contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\n",
      "the effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\n",
      "has been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\n",
      "attention and the parameter-free position representation and became the other person involved in nearly every\n",
      "detail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\n",
      "tensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\n",
      "efficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\n",
      "implementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\n",
      "our research.\n",
      "†Work performed while at Google Brain.\n",
      "‡Work performed while at Google Research.\n",
      "31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0][\"page_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Introduction\n",
      "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\n",
      "in particular, have been firmly established as state of the art approaches in sequence modeling and\n",
      "transduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\n",
      "efforts have since continued to push the boundaries of recurrent language models and encoder-decoder\n",
      "architectures [38, 24, 15].\n",
      "Recurrent models typically factor computation along the symbol positions of the input and output\n",
      "sequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\n",
      "states h , as a function of the previous hidden state h and the input for position t. This inherently\n",
      "t t−1\n",
      "sequential nature precludes parallelization within training examples, which becomes critical at longer\n",
      "sequence lengths, as memory constraints limit batching across examples. Recent work has achieved\n",
      "significant improvements in computational efficiency through factorization tricks [21] and conditional\n",
      "computation [32], while also improving model performance in case of the latter. The fundamental\n",
      "constraint of sequential computation, however, remains.\n",
      "Attention mechanisms have become an integral part of compelling sequence modeling and transduc-\n",
      "tion models in various tasks, allowing modeling of dependencies without regard to their distance in\n",
      "the input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\n",
      "are used in conjunction with a recurrent network.\n",
      "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
      "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
      "The Transformer allows for significantly more parallelization and can reach a new state of the art in\n",
      "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
      "2 Background\n",
      "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
      "[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\n",
      "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
      "the number of operations required to relate signals from two arbitrary input or output positions grows\n",
      "in the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\n",
      "it more difficult to learn dependencies between distant positions [12]. In the Transformer this is\n",
      "reduced to a constant number of operations, albeit at the cost of reduced effective resolution due\n",
      "to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\n",
      "described in section 3.2.\n",
      "Self-attention, sometimes called intra-attention is an attention mechanism relating different positions\n",
      "of a single sequence in order to compute a representation of the sequence. Self-attention has been\n",
      "used successfully in a variety of tasks including reading comprehension, abstractive summarization,\n",
      "textual entailment and learning task-independent sentence representations [4, 27, 28, 22].\n",
      "End-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\n",
      "aligned recurrence and have been shown to perform well on simple-language question answering and\n",
      "language modeling tasks [34].\n",
      "To the best of our knowledge, however, the Transformer is the first transduction model relying\n",
      "entirely on self-attention to compute representations of its input and output without using sequence-\n",
      "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
      "self-attention and discuss its advantages over models such as [17, 18] and [9].\n",
      "3 Model Architecture\n",
      "Most competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\n",
      "Here, the encoder maps an input sequence of symbol representations (x , ..., x ) to a sequence\n",
      "1 n\n",
      "of continuous representations z = (z , ..., z ). Given z, the decoder then generates an output\n",
      "1 n\n",
      "sequence (y , ..., y ) of symbols one element at a time. At each step the model is auto-regressive\n",
      "1 m\n",
      "[10], consuming the previously generated symbols as additional input when generating the next.\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[1][\"page_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (rule_short):   0%|          | 0/507 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (rule_short): 100%|██████████| 507/507 [00:01<00:00, 370.35it/s]\n",
      "create documents... (rule_long): 100%|██████████| 124/124 [00:00<00:00, 383.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>0</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>1</td>\n",
       "      <td>reproduce the tables and figures in this paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>2</td>\n",
       "      <td>Attention Is All You Need\\n3202 guA 2  ]LC.sc[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>3</td>\n",
       "      <td>Google Brain Google Brain Google Research Goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>4</td>\n",
       "      <td>†\\nLlion Jones∗ Aidan N. Gomez∗ Łukasz Kaiser∗...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>119</td>\n",
       "      <td>|    | p     | u     | t-     | In      | p   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>120</td>\n",
       "      <td>|  0 |       |       |        |         |     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>15</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>121</td>\n",
       "      <td>|  2 | ehT   | waL   | lliw   | reven   | eb  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>15</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>122</td>\n",
       "      <td>|  4 |       |       |        |         |     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>15</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>123</td>\n",
       "      <td>noinipo &gt;SOE&lt;\\nnoitacilppa\\nFigure 5: Many of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number  chunk_type  chunk_id  \\\n",
       "0              1  rule_short         0   \n",
       "1              1  rule_short         1   \n",
       "2              1  rule_short         2   \n",
       "3              1  rule_short         3   \n",
       "4              1  rule_short         4   \n",
       "..           ...         ...       ...   \n",
       "626            2   rule_long       119   \n",
       "627            1   rule_long       120   \n",
       "628           15   rule_long       121   \n",
       "629           15   rule_long       122   \n",
       "630           15   rule_long       123   \n",
       "\n",
       "                                         chunk_content  \n",
       "0    Provided proper attribution is provided, Googl...  \n",
       "1    reproduce the tables and figures in this paper...  \n",
       "2    Attention Is All You Need\\n3202 guA 2  ]LC.sc[...  \n",
       "3    Google Brain Google Brain Google Research Goog...  \n",
       "4    †\\nLlion Jones∗ Aidan N. Gomez∗ Łukasz Kaiser∗...  \n",
       "..                                                 ...  \n",
       "626  |    | p     | u     | t-     | In      | p   ...  \n",
       "627  |  0 |       |       |        |         |     ...  \n",
       "628  |  2 | ehT   | waL   | lliw   | reven   | eb  ...  \n",
       "629  |  4 |       |       |        |         |     ...  \n",
       "630  noinipo >SOE<\\nnoitacilppa\\nFigure 5: Many of ...  \n",
       "\n",
       "[631 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = RuleBasedTextChunker()\n",
    "chunks = chunker.chunk(df)\n",
    "total_chunks = next(chunks)\n",
    "print(total_chunks)\n",
    "df_chunk = []\n",
    "for chunk in chunks:\n",
    "    df_chunk.append(chunk)\n",
    "df_chunk = pd.DataFrame(df_chunk)\n",
    "df_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMBasedTextChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frony_document_manager.parser_dev import ParserPDF\n",
    "from frony_document_manager.chunker_dev import LLMBasedTextChunker\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# from tqdm import tqdm\n",
    "# from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# from transformers import AutoTokenizer\n",
    "# from openai import OpenAI\n",
    "# import Levenshtein\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Providedproperattributionisprovided,Googlehere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1 Introduction\\nRecurrentneuralnetworks,longsh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Figure1: TheTransformer-modelarchitecture.\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ScaledDot-ProductAttention Multi-HeadAttention...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>output values. These are concatenated and once...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Table1: Maximumpathlengths,per-layercomplexity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>n d,\\nlength is smaller than the representatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Table2: TheTransformerachievesbetterBLEUscores...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Table3: VariationsontheTransformerarchitecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Table4: TheTransformergeneralizeswelltoEnglish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[5] KyunghyunCho,BartvanMerrienboer,CaglarGulc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[25] MitchellPMarcus,MaryAnnMarcinkiewicz,andB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|    | Vi   | atio   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|--:|\\n| 0 |\\n| 1 |\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|--:|\\n| 0 |\\n| 1 |\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                       page_content\n",
       "0             1  Providedproperattributionisprovided,Googlehere...\n",
       "1             2  1 Introduction\\nRecurrentneuralnetworks,longsh...\n",
       "2             3  Figure1: TheTransformer-modelarchitecture.\\nTh...\n",
       "3             4  ScaledDot-ProductAttention Multi-HeadAttention...\n",
       "4             5  output values. These are concatenated and once...\n",
       "5             6  Table1: Maximumpathlengths,per-layercomplexity...\n",
       "6             7  n d,\\nlength is smaller than the representatio...\n",
       "7             8  Table2: TheTransformerachievesbetterBLEUscores...\n",
       "8             9  Table3: VariationsontheTransformerarchitecture...\n",
       "9            10  Table4: TheTransformergeneralizeswelltoEnglish...\n",
       "10           11  [5] KyunghyunCho,BartvanMerrienboer,CaglarGulc...\n",
       "11           12  [25] MitchellPMarcus,MaryAnnMarcinkiewicz,andB...\n",
       "12           13  Input-Input Layer5\\n<표>\\n|    | Vi   | atio   ...\n",
       "13           14  Input-Input Layer5\\n<표>\\n|--:|\\n| 0 |\\n| 1 |\\n...\n",
       "14           15  Input-Input Layer5\\n<표>\\n|--:|\\n| 0 |\\n| 1 |\\n..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ParserPDF()\n",
    "df = parser.parse(\"test_files/test_pdf.pdf\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (812 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (llm_text): 100%|██████████| 15/15 [01:08<00:00,  4.55s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n#### 1. 논문의 목적 및 배경\\n이 논문에서는 기존의...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n1. **모델 성능 및 실험 결과**\\n   - 새로운 기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n1. **모델 개발 및 평가**:\\n   - Nik은 원래...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 서론\\n순환 신경망(Recurrent Neural Networks), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 주제: 시퀀스 모델링의 제약\\n- 시퀀스 컴퓨테이션의 제약이 여전히 존...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 신호 처리 및 연산 요구 사항\\n- 두 임의의 입력 또는 출력 위치 간...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. Transformer 모델의 개요\\n- Transformer는 입력과 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>**주제: Transformer 모델 아키텍처**\\n\\n1. **전반적인 구조**\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 디코더 구조\\n디코더는 각 인코더 레이어에 두 개의 서브 레이어 외에 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. Scaled Dot-Product Attention\\n- **정의**:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. Attention Mechanisms\\n- **Dot-Product A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>주제별 요약:\\n\\n1. **선형 프로젝션**: \\n   - k, q, v 쿼리, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n#### 1. 다중 헤드 주의(Multi-head Atte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 인코더-디코더 주의 메커니즘\\n- 인코더-디코더 주의 레이어에서 쿼리는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 피드포워드 네트워크\\n- 인코더와 디코더의 각 레이어는 주의 하위 레이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number chunk_type  chunk_id  \\\n",
       "0             1   llm_text         0   \n",
       "1             1   llm_text         0   \n",
       "2             1   llm_text         0   \n",
       "3             1   llm_text         0   \n",
       "4             2   llm_text         0   \n",
       "5             2   llm_text         0   \n",
       "6             2   llm_text         0   \n",
       "7             3   llm_text         0   \n",
       "8             3   llm_text         0   \n",
       "9             3   llm_text         0   \n",
       "10            4   llm_text         0   \n",
       "11            4   llm_text         0   \n",
       "12            4   llm_text         0   \n",
       "13            5   llm_text         0   \n",
       "14            5   llm_text         0   \n",
       "\n",
       "                                        chunk_content  \n",
       "0   ### 주제별 요약\\n\\n#### 1. 논문의 목적 및 배경\\n이 논문에서는 기존의...  \n",
       "1   ### 주제별 요약\\n\\n1. **모델 성능 및 실험 결과**\\n   - 새로운 기...  \n",
       "2   ### 주제별 요약\\n\\n1. **모델 개발 및 평가**:\\n   - Nik은 원래...  \n",
       "3   ### 1. 서론\\n순환 신경망(Recurrent Neural Networks), ...  \n",
       "4   ### 1. 주제: 시퀀스 모델링의 제약\\n- 시퀀스 컴퓨테이션의 제약이 여전히 존...  \n",
       "5   ### 1. 신호 처리 및 연산 요구 사항\\n- 두 임의의 입력 또는 출력 위치 간...  \n",
       "6   ### 1. Transformer 모델의 개요\\n- Transformer는 입력과 ...  \n",
       "7   **주제: Transformer 모델 아키텍처**\\n\\n1. **전반적인 구조**\\...  \n",
       "8   ### 1. 디코더 구조\\n디코더는 각 인코더 레이어에 두 개의 서브 레이어 외에 ...  \n",
       "9   ### 1. Scaled Dot-Product Attention\\n- **정의**:...  \n",
       "10  ### 1. Attention Mechanisms\\n- **Dot-Product A...  \n",
       "11  주제별 요약:\\n\\n1. **선형 프로젝션**: \\n   - k, q, v 쿼리, ...  \n",
       "12  ### 주제별 요약\\n\\n#### 1. 다중 헤드 주의(Multi-head Atte...  \n",
       "13  ### 1. 인코더-디코더 주의 메커니즘\\n- 인코더-디코더 주의 레이어에서 쿼리는...  \n",
       "14  ### 1. 피드포워드 네트워크\\n- 인코더와 디코더의 각 레이어는 주의 하위 레이...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = LLMBasedTextChunker(tokenizer_path=\"google-bert/bert-base-uncased\", n_gram=2)\n",
    "chunks = chunker.chunk(\n",
    "    df.iloc[:5],\n",
    "    splitter_config=[\n",
    "        {\"type\": \"llm_text\", \"params\": {\"chunk_size\": 512, \"chunk_overlap\": 512 // 4}},\n",
    "    ]\n",
    ")\n",
    "total_chunks = next(chunks)\n",
    "print(total_chunks)\n",
    "df_chunk = []\n",
    "for chunk in chunks:\n",
    "    df_chunk.append(chunk)\n",
    "df_chunk = pd.DataFrame(df_chunk)\n",
    "df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (llm_text):   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (llm_text): 100%|██████████| 10/10 [00:51<00:00,  5.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n#### 1. 연구 배경 및 목적\\n- 기존의 시퀀스 변환...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n1. **연구 배경 및 목표**:\\n   - 연구는 영어 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 서론\\n순환 신경망(Recurrent Neural Networks, R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 배경\\n- **목표**: 순차적 계산을 줄이는 것이 Extended N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n#### 1. Transformer 및 Self-Atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. Transformer 모델 아키텍처\\n- Transformer 모델은 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n#### 1. Scaled Dot-Product Atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n1. **문제점 및 해결책**\\n   - 매우 작은 기울기...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 멀티 헤드 어텐션 (Multi-head Attention)\\n- 멀티 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>llm_text</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 디코더의 정보 흐름 차단\\n- 디코더에서 왼쪽으로 정보 흐름이 발생하지...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number chunk_type  chunk_id  \\\n",
       "0            1   llm_text         0   \n",
       "1            1   llm_text         0   \n",
       "2            2   llm_text         0   \n",
       "3            2   llm_text         0   \n",
       "4            2   llm_text         0   \n",
       "5            3   llm_text         0   \n",
       "6            4   llm_text         0   \n",
       "7            4   llm_text         0   \n",
       "8            4   llm_text         0   \n",
       "9            5   llm_text         0   \n",
       "\n",
       "                                       chunk_content  \n",
       "0  ### 주제별 요약\\n\\n#### 1. 연구 배경 및 목적\\n- 기존의 시퀀스 변환...  \n",
       "1  ### 주제별 요약\\n\\n1. **연구 배경 및 목표**:\\n   - 연구는 영어 ...  \n",
       "2  ### 1. 서론\\n순환 신경망(Recurrent Neural Networks, R...  \n",
       "3  ### 1. 배경\\n- **목표**: 순차적 계산을 줄이는 것이 Extended N...  \n",
       "4  ### 주제별 요약\\n\\n#### 1. Transformer 및 Self-Atten...  \n",
       "5  ### 1. Transformer 모델 아키텍처\\n- Transformer 모델은 ...  \n",
       "6  ### 주제별 요약\\n\\n#### 1. Scaled Dot-Product Atten...  \n",
       "7  ### 주제별 요약\\n\\n1. **문제점 및 해결책**\\n   - 매우 작은 기울기...  \n",
       "8  ### 1. 멀티 헤드 어텐션 (Multi-head Attention)\\n- 멀티 ...  \n",
       "9  ### 1. 디코더의 정보 흐름 차단\\n- 디코더에서 왼쪽으로 정보 흐름이 발생하지...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = LLMBasedTextChunker(n_gram=2)\n",
    "chunks = chunker.chunk(\n",
    "    df.iloc[:5],\n",
    "    splitter_config=[\n",
    "        {\"type\": \"llm_text\", \"params\": {\"chunk_size\": 2048, \"chunk_overlap\": 2048 // 4}},\n",
    "    ]\n",
    ")\n",
    "total_chunks = next(chunks)\n",
    "print(total_chunks)\n",
    "df_chunk = []\n",
    "for chunk in chunks:\n",
    "    df_chunk.append(chunk)\n",
    "df_chunk = pd.DataFrame(df_chunk)\n",
    "df_chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLMBasedImageChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                       page_content\n",
       "0             1  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "1             2  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "2             3  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "3             4  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "4             5  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "5             6  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "6             7  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "7             8  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "8             9  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "9            10  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "10           11  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "11           12  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "12           13  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "13           14  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA...\n",
       "14           15  iVBORw0KGgoAAAANSUhEUgAACfYAAAzlCAIAAABT38lbAA..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ParserPDFImage()\n",
    "df = parser.parse(\"test_files/test_pdf.pdf\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (llm_image):   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (llm_image): 100%|██████████| 5/5 [00:33<00:00,  6.65s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>llm_image</td>\n",
       "      <td>0</td>\n",
       "      <td>논문 \"Attention Is All You Need\"의 요약은 다음과 같습니다.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>llm_image</td>\n",
       "      <td>0</td>\n",
       "      <td>### 1. 서론\\n- **재귀 신경망**: 언어 모델링과 기계 번역에서 주류 방법...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>llm_image</td>\n",
       "      <td>0</td>\n",
       "      <td>이미지는 Transformer 모델 아키텍처에 대한 설명을 포함하고 있습니다. 다음...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>llm_image</td>\n",
       "      <td>0</td>\n",
       "      <td>### 주제별 요약\\n\\n#### 1. Scaled Dot-Product Atten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>llm_image</td>\n",
       "      <td>0</td>\n",
       "      <td>다음은 주제별로 요약한 내용입니다.\\n\\n### 1. 멀티헤드 어텐션\\n- 멀티헤드...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number chunk_type  chunk_id  \\\n",
       "0            1  llm_image         0   \n",
       "1            2  llm_image         0   \n",
       "2            3  llm_image         0   \n",
       "3            4  llm_image         0   \n",
       "4            5  llm_image         0   \n",
       "\n",
       "                                       chunk_content  \n",
       "0  논문 \"Attention Is All You Need\"의 요약은 다음과 같습니다.\\...  \n",
       "1  ### 1. 서론\\n- **재귀 신경망**: 언어 모델링과 기계 번역에서 주류 방법...  \n",
       "2  이미지는 Transformer 모델 아키텍처에 대한 설명을 포함하고 있습니다. 다음...  \n",
       "3  ### 주제별 요약\\n\\n#### 1. Scaled Dot-Product Atten...  \n",
       "4  다음은 주제별로 요약한 내용입니다.\\n\\n### 1. 멀티헤드 어텐션\\n- 멀티헤드...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = LLMBasedImageChunker()\n",
    "chunks = chunker.chunk(df.iloc[:5])\n",
    "total_chunks = next(chunks)\n",
    "print(total_chunks)\n",
    "df_chunk = []\n",
    "for chunk in chunks:\n",
    "    df_chunk.append(chunk)\n",
    "df_chunk = pd.DataFrame(df_chunk)\n",
    "df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-chunker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
