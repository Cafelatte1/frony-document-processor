{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NTELS\\miniconda3\\envs\\doc-chunker\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from frony_document_processor.parser import ParserTXT\n",
    "from frony_document_processor.parser import ParserPDF\n",
    "from frony_document_processor.parser import ParserPPTX\n",
    "from frony_document_processor.parser import ParserPDFImage\n",
    "from frony_document_processor.parser import ParserImage\n",
    "\n",
    "from frony_document_processor.chunker import RuleBasedTextChunker\n",
    "from frony_document_processor.chunker import LLMBasedTextChunker\n",
    "from frony_document_processor.chunker import LLMBasedImageChunker\n",
    "\n",
    "from frony_document_processor.embedder import OpenAIEmbedder\n",
    "from frony_document_processor.embedder import SentenceTransformerEmbedder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RuleBasedTextChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1 Introduction\\nRecurrent neural networks, lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Figure 1: The Transformer - model architecture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Scaled Dot-Product Attention Multi-Head Attent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>output values. These are concatenated and once...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Table 1: Maximum path lengths, per-layer compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>n\\nlength is smaller than the representation d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Table 2: The Transformer achieves better BLEU ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Table 3: Variations on the Transformer archite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Table 4: The Transformer generalizes well to E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>[5] Kyunghyun Cho, Bart van Merrienboer, Cagla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>[25] Mitchell P Marcus, Mary Ann Marcinkiewicz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|    | Vi   | atio   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|--:|\\n| 0 |\\n| 1 |\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Input-Input Layer5\\n&lt;표&gt;\\n|--:|\\n| 0 |\\n| 1 |\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    page_number                                       page_content\n",
       "0             1  Provided proper attribution is provided, Googl...\n",
       "1             2  1 Introduction\\nRecurrent neural networks, lon...\n",
       "2             3  Figure 1: The Transformer - model architecture...\n",
       "3             4  Scaled Dot-Product Attention Multi-Head Attent...\n",
       "4             5  output values. These are concatenated and once...\n",
       "5             6  Table 1: Maximum path lengths, per-layer compl...\n",
       "6             7  n\\nlength is smaller than the representation d...\n",
       "7             8  Table 2: The Transformer achieves better BLEU ...\n",
       "8             9  Table 3: Variations on the Transformer archite...\n",
       "9            10  Table 4: The Transformer generalizes well to E...\n",
       "10           11  [5] Kyunghyun Cho, Bart van Merrienboer, Cagla...\n",
       "11           12  [25] Mitchell P Marcus, Mary Ann Marcinkiewicz...\n",
       "12           13  Input-Input Layer5\\n<표>\\n|    | Vi   | atio   ...\n",
       "13           14  Input-Input Layer5\\n<표>\\n|--:|\\n| 0 |\\n| 1 |\\n...\n",
       "14           15  Input-Input Layer5\\n<표>\\n|--:|\\n| 0 |\\n| 1 |\\n..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ParserPDF()\n",
    "df = parser.parse(\"test_files/test_pdf.pdf\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create documents... (rule_short): 100%|██████████| 507/507 [00:01<00:00, 376.55it/s]\n",
      "create documents... (rule_long): 100%|██████████| 124/124 [00:00<00:00, 401.36it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_type</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>chunk_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>0</td>\n",
       "      <td>Provided proper attribution is provided, Googl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>1</td>\n",
       "      <td>reproduce the tables and figures in this paper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>2</td>\n",
       "      <td>Attention Is All You Need\\n3202 guA 2  ]LC.sc[...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>3</td>\n",
       "      <td>Google Brain Google Brain Google Research Goog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_short</td>\n",
       "      <td>4</td>\n",
       "      <td>†\\nLlion Jones∗ Aidan N. Gomez∗ Łukasz Kaiser∗...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>2</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>119</td>\n",
       "      <td>|    | p     | u     | t-     | In      | p   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>1</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>120</td>\n",
       "      <td>|  0 |       |       |        |         |     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>15</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>121</td>\n",
       "      <td>|  2 | ehT   | waL   | lliw   | reven   | eb  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>15</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>122</td>\n",
       "      <td>|  4 |       |       |        |         |     ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>15</td>\n",
       "      <td>rule_long</td>\n",
       "      <td>123</td>\n",
       "      <td>noinipo &gt;SOE&lt;\\nnoitacilppa\\nFigure 5: Many of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     page_number  chunk_type  chunk_id  \\\n",
       "0              1  rule_short         0   \n",
       "1              1  rule_short         1   \n",
       "2              1  rule_short         2   \n",
       "3              1  rule_short         3   \n",
       "4              1  rule_short         4   \n",
       "..           ...         ...       ...   \n",
       "626            2   rule_long       119   \n",
       "627            1   rule_long       120   \n",
       "628           15   rule_long       121   \n",
       "629           15   rule_long       122   \n",
       "630           15   rule_long       123   \n",
       "\n",
       "                                         chunk_content  \n",
       "0    Provided proper attribution is provided, Googl...  \n",
       "1    reproduce the tables and figures in this paper...  \n",
       "2    Attention Is All You Need\\n3202 guA 2  ]LC.sc[...  \n",
       "3    Google Brain Google Brain Google Research Goog...  \n",
       "4    †\\nLlion Jones∗ Aidan N. Gomez∗ Łukasz Kaiser∗...  \n",
       "..                                                 ...  \n",
       "626  |    | p     | u     | t-     | In      | p   ...  \n",
       "627  |  0 |       |       |        |         |     ...  \n",
       "628  |  2 | ehT   | waL   | lliw   | reven   | eb  ...  \n",
       "629  |  4 |       |       |        |         |     ...  \n",
       "630  noinipo >SOE<\\nnoitacilppa\\nFigure 5: Many of ...  \n",
       "\n",
       "[631 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunker = RuleBasedTextChunker()\n",
    "chunks = chunker.chunk(df)\n",
    "total_chunks = next(chunks)\n",
    "print(total_chunks)\n",
    "df_chunk = []\n",
    "for chunk in chunks:\n",
    "    df_chunk.append(chunk)\n",
    "df_chunk = pd.DataFrame(df_chunk)\n",
    "df_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(631, 1536)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder = OpenAIEmbedder(model_id=\"text-embedding-3-small\", embed_dim=1536)\n",
    "embed = embedder.embed(df_chunk[\"chunk_content\"].to_list())\n",
    "print(len(embed))\n",
    "np.array(embed).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "class SentenceTransformerEmbedder():\n",
    "    def __init__(self, model_id: str, embed_dim: int, device: str = \"cpu\", precision: str = \"fp16\"):\n",
    "        self.model = SentenceTransformer(model_id, device=device)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.precision = precision\n",
    "\n",
    "    def embed(self, data: str | List[str], batch_size: int = 4):\n",
    "        data = [data] if isinstance(data, str) else data\n",
    "        sorted = np.array([len(i) for i in data]).argsort()\n",
    "        embed = self.model.encode([data[i] for i in sorted], batch_size=batch_size, normalize_embeddings=True, convert_to_tensor=True)\n",
    "        embed = embed.half() if self.precision == \"fp16\" else embed\n",
    "        embed[sorted] = embed.clone()\n",
    "        embed = embed.tolist()\n",
    "        return embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformerEmbedder(model_id=\"all-MiniLM-L6-v2\", embed_dim=384, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 24.2 s\n",
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embed = embedder.embed(df_chunk[\"chunk_content\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.1151123 ,  0.01026154,  0.00456619, -0.05773926,  0.05285645,\n",
       "       -0.01487732,  0.03738403, -0.07794189, -0.00886536,  0.00239754])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(embed))\n",
    "np.array(embed)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 26.5 s\n",
      "Wall time: 7.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "embed = embedder.model.encode(df_chunk[\"chunk_content\"].to_list(), batch_size=4, normalize_embeddings=True, convert_to_tensor=True).half().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.1151123 ,  0.01026154,  0.00456619, -0.05773926,  0.05285645,\n",
       "       -0.01487732,  0.03738403, -0.07794189, -0.00886536,  0.00239754])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(embed))\n",
    "np.array(embed)[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509    convolutional neural networks that include an ...\n",
       "271    |    |      | 4                               ...\n",
       "218    1 2\\nrate over the course of training, accordi...\n",
       "145    The dimensionality of input and output is d = ...\n",
       "495    ni   | ym   | noinipo   | .   | >SOE<   | >dap...\n",
       "                             ...                        \n",
       "71     1 n\\nsequence (y , ..., y ) of symbols one ele...\n",
       "106    √1\\nof . Additive attention computes the compa...\n",
       "270    |  3 | (C)  | 2                               ...\n",
       "435    |    | tir   | ta   | yt   | n   | st   | e   ...\n",
       "102    into a matrix Q. The keys and values are also ...\n",
       "Name: chunk_content, Length: 631, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunk[\"chunk_content\"].sample(frac=1.0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "doc-chunker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
